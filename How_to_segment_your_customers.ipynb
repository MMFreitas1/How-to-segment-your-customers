{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report on Customer Segmentation\n",
    "\n",
    "![Banner](Images/Banner.jpg)\n",
    "\n",
    "\n",
    "## The following report is divided into 6 stages:\n",
    "* __Background__ - Gives context to this report\n",
    "* __The Data__ - The data available for analysis\n",
    "    *  Doctors contains information on doctors. Each row represents one doctor.\n",
    "    *  Orders contains details on orders. Each row represents one order; a doctor can place multiple orders.\n",
    "    *  Complaints collects information on doctor complaints.\n",
    "    *  Instructions has information on whether the doctor includes special instructions on their orders.\n",
    "* __Methodology__ - Explains methods used to achieve results\n",
    "* __What the managers wants to know?__ - Answering specific questions through statistic analysis and Machine Learning\n",
    "    * How many doctors are there in each region? What is the average number of purchases per region?\n",
    "    * Can you find a relationship between purchases and complaints?\n",
    "    * Define new doctor segments that help the company improve marketing efforts and customer service.\n",
    "    * Identify which features impact the new segmentation strategy the most.\n",
    "    * Your team will need to explain the new segments to the rest of the company. Describe which characteristics distinguish the newly defined segments.\n",
    "* __Recommendations__ - My interpretation of the personas, with insights to the marketing team\n",
    "* __Appendix__ - Overall code used in the tasks\n",
    "    * Code for questions of analysis\n",
    "    * Code of ML pipeline for repeatability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can you find a better way to segment your customers?\n",
    "\n",
    "## üìñ Background\n",
    "I work as a Data Scientist in a medical device manufacturer in Switzerland called Johansson & Johansson, a company that manufactures orthopedic devices and sells them worldwide, directly to individual doctors who use them on rehabilitation and physical therapy patients.\n",
    "\n",
    "Historically, the sales and customer support departments have grouped doctors by geography. However, the region is not a good predictor of the number of purchases a doctor will make or their support needs.\n",
    "\n",
    "My team wants to use a data-centric approach to segmenting doctors to improve marketing, customer service, and product planning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ The Data\n",
    "\n",
    "The company stores the information you need in the following four tables. Some of the fields are anonymized to comply with privacy regulations.\n",
    "\n",
    "#### Doctors contains information on doctors. Each row represents one doctor.\n",
    "- \"DoctorID\" - is a unique identifier for each doctor.\n",
    "- \"Region\" - the current geographical region of the doctor.\n",
    "- \"Category\" - the type of doctor, either 'Specialist' or 'General Practitioner.'\n",
    "- \"Rank\" - is an internal ranking system. It is an ordered variable: The highest level is Ambassadors, followed by Titanium Plus, Titanium, Platinum Plus, Platinum, Gold Plus, Gold, Silver Plus, and the lowest level is Silver.\n",
    "- \"Incidence rate\"  and \"R rate\" - relate to the amount of re-work each doctor generates.\n",
    "- \"Satisfaction\" - measures doctors' satisfaction with the company.\n",
    "- \"Experience\" - relates to the doctor's experience with the company.\n",
    "- \"Purchases\" - purchases over the last year.\n",
    "\n",
    "#### Orders contains details on orders. Each row represents one order; a doctor can place multiple orders.\n",
    "- \"DoctorID\" - doctor id (matches the other tables).\n",
    "- \"OrderID\" - order identifier.\n",
    "- \"OrderNum\" - order number.\n",
    "- \"Conditions A through J\" - map the different settings of the devices in each order. Each order goes to an individual patient.\n",
    "\n",
    "#### Complaints collects information on doctor complaints.\n",
    "- \"DoctorID\" - doctor id (matches the other tables).\n",
    "- \"Complaint Type\" - the company's classification of the complaints.\n",
    "- \"Qty\" - number of complaints per complaint type per doctor.\n",
    "\n",
    "#### Instructions has information on whether the doctor includes special instructions on their orders.\n",
    "- \"DoctorID\" - doctor id (matches the other tables).\n",
    "- \"Instructions\" - 'Yes' when the doctor includes special instructions, 'No' when they do not."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Methodology\n",
    "\n",
    "In order to reach to a conclusion on how customers are segmented on our data, an approach using unsupervised machine learning was used, as it is easy to interpretate and not computationally heavy.\n",
    "\n",
    "For the algorithm to be able to process the data correctly:\n",
    "1. After cleaning the data, a set of ordinal and continuous variables were selected to be processed\n",
    "2. The ordinal variable was label-encoded so it could represent a numerical rank and consequentially, enabling it to be processed\n",
    "3. Since the K-means algorithm is sensible to distances (huge numerical sizes), the selected variables needed to be normalized\n",
    "4. As a tentative to reduce the dimentionality (number of variables) of the data, since the selected variables were already normalized, a Principal Component Analysis could be performed\n",
    "5. After observing that 5 out of 7 Principal Components explain more than 80% of the data, those 2 Principal Components were discarded\n",
    "6. The re-dimensioned data was then fed to the K-means, with a choosed \"k\" of 4 clusters\n",
    "7. The resulting labels were then added to the data, where the features of analysis were grouped by each label and displaying the mean value to assist the interpretability of the clusters, thus creating the segments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìñ What the managers want to know?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üëâ How many doctors are there in each region? What is the average number of purchases per region?\n",
    "\n",
    "Sometimes due to demographic factors, the distribution of doctors are not the same throughout a given area. Even so, we find a some regions with particularly high averages and other with less, as per below\n",
    "\n",
    "![Average purchases per region](Images/Average_purchases_per_region.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üëâ Can you find a relationship between purchases and complaints?\n",
    "\n",
    "Naturally, the more a business scales and more sales are made, in general, the more complaints will be, in a proportionate manner (assuming \"business as usual\" conditions).\n",
    "By performing a correlation test between the two variables, we can draw conclusions about their correlation and significance level. As per the scatterplot below, with complaints as a function of purchases, we see a __week correlation__ of 0.16, and a __significance level__ of less than 0.05.\n",
    "\n",
    "This means __the variables are indeed correlated__, the higher the purchases are, the higher the complaints will be. The outliers were accounted for later on, since we have a \"balance\" our outliers in both axis, nontheless, we can see a week correlation. Something else may having a higher impact on the complaints variable. \n",
    "\n",
    "![Correlation between Purchases and Complaints](Images/Correlation_between_Purchases_and_Complaints.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üëâ Define new doctor segments that help the company improve marketing efforts and customer service.\n",
    "\n",
    "After segmenting the data through unsupervised machine learning, I've decided to highlight 4 customer segments with defined characteristics:\n",
    "\n",
    "![Personas distribution](Images/Personas_distribution.jpg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üëâ Identify which features impact the new segmentation strategy the most.\n",
    "\n",
    "![Main features](Images/Main_features.jpg)\n",
    "\n",
    "![Personas average values](Images/Personas_average_values.jpg)\n",
    "\n",
    "Of all the features present in the 4 data sets, only a few were selected to cluster our customets.\n",
    "As per the table above, these were the features used to model the segmentation strategy and they all play an important role in shaping the personas' characteristics and understanding their behavior.\n",
    "\n",
    "The  Incidence Rate and R rate are interpreted as a whole, which I address as \"re-work\", and the variable Qty refers to Complaints.\n",
    "\n",
    "* 0/ __Millenial__\n",
    "* 1/ __Fan__\n",
    "* 2/ __Bootstrapper__\n",
    "* 3/ __Conservative__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üëâ Your team will need to explain the new segments to the rest of the company. Describe which characteristics distinguish the newly defined segments.\n",
    "\n",
    "The different combination of said variables will slowly reveal behavior traits, that easily distinguish each segment: \n",
    "\n",
    "![Persona's characteristics](Images/Personas_characteristics.jpg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úçüèΩ Recommendations\n",
    "We should maintain the good service with the __Fan__, and above all, improve the quality of the service of the __Bootstrapper__. Since the latter is the persona that represents our data the most, having a first good impression may play a role in their retention levels. In turn, this may increase their interest and curiosity, leading to an upgrade of the  subscription plan, resulting in the improvement of Johansson & Johansson's brand image and profits.\n",
    "\n",
    "Regarding our __Conservative__, they seem to be an example of what happens when customers below the higher rankings behave when they reach maturity. Efforts should be deployed to maintain them engaged with the company for longer.\n",
    "Now, about the __Millennial__, although smaller in numbers, they have a purchasing behaviour that does not imply cost savings, however, they do complaint a lot. To unearth the reason of such behavior, the complaints must be analyzed, for example, DoctorID #FAICB shows 5 times in the top 10 number of complaints per order, and this podium is all comprised of the __Milleannial__ persona."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÑ Appendix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for the questions of analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and inspect data\n",
    "doctors = pd.read_csv(\"Data/doctors.csv\")\n",
    "display(doctors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and inspect data\n",
    "orders = pd.read_csv(\"Data/orders.csv\")\n",
    "display(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and inspect data\n",
    "complaints = pd.read_csv(\"Data/complaints.csv\")\n",
    "display(complaints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and inspect data\n",
    "instructions = pd.read_csv(\"Data/instructions.csv\")\n",
    "display(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtaining number of doctors and average purchases per region, ordered by doctors\n",
    "purchase_per_region = doctors.groupby(\"Region\")[\"Purchases\"].mean()\n",
    "dr_per_region = doctors.Region.value_counts().sort_index()\n",
    "dr_per_region = dr_per_region.reset_index(drop = False).set_index(\"Region\")\n",
    "dr_per_region[\"avg_purchases\"] = purchase_per_region.values\n",
    "\n",
    "#\n",
    "dr = dr_per_region[\"count\"]\n",
    "pur = dr_per_region[\"avg_purchases\"]\n",
    "\n",
    "#Plotting findings\n",
    "plt.figure(figsize = (10, 8))\n",
    "dr.plot(kind = \"barh\", width= 1 , color = \"green\", edgecolor = \"black\", alpha = 0.8, label = \"Doctors\")\n",
    "pur.plot(kind = \"barh\", width= 1, color = \"white\", edgecolor = \"black\", alpha = 0.8, label = \"Purchases\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xticks(range(0, 131, 10))\n",
    "plt.grid(True, axis = \"x\")\n",
    "plt.title(\"Graph #1 - Number of Doctors and Average Purchases per Region\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtaining number of complaints per Doctor\n",
    "complaints_per_doctor = complaints.groupby(\"DoctorID\", as_index = False)[\"Qty\"]\\\n",
    "                                    .sum()\\\n",
    "                                    .sort_values(\"Qty\", ascending = False)\n",
    "\n",
    "#Merging findings with the \"doctors\" data set\n",
    "doctors_complaints_merged = doctors.merge(complaints_per_doctor, on = \"DoctorID\", how = \"left\", validate = \"one_to_one\")\n",
    "\n",
    "#Filling missing values with 0, meaning no complaints were made\n",
    "doctors_complaints_merged.Qty.fillna(0, inplace = True)\n",
    "\n",
    "#Checking for relationship between purchases and complaints\n",
    "y = doctors_complaints_merged.Qty\n",
    "x = doctors_complaints_merged.Purchases\n",
    "statistic, pvalue = stats.pearsonr(x, y)\n",
    "\n",
    "#Plotting findings\n",
    "sns.lmplot(x = \"Purchases\", y = \"Qty\", data = doctors_complaints_merged, ci = None,\\\n",
    "           y_jitter = True, scatter_kws = {\"alpha\" : 0.3},\\\n",
    "           line_kws = {\"color\" : \"g\",\n",
    "                    \"linewidth\" : 0.8})\n",
    "plt.title(\"Graph #2 - Correlation between Purchases and Complaints\")\n",
    "plt.annotate(f\"R2 = {round(statistic, 2)}\", (80.0, 17.5))\n",
    "plt.annotate(f\"p-value = {round(pvalue, 4)}\", (80.0, 16.5))\n",
    "plt.ylabel(\"Complaints\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling two Rank missing values with median\n",
    "mode = doctors_complaints_merged[\"Rank\"].mode()[0]\n",
    "doctors_complaints_merged[\"Rank\"].fillna(mode, inplace = True)\n",
    "\n",
    "#Changing Rank ordinal variable to numeric\n",
    "doctors_complaints_merged[\"Rank\"] = doctors_complaints_merged.Rank.map({\"Silver\": 0,\n",
    "                               \"Silver Plus\": 1,\n",
    "                               \"Gold\": 2,\n",
    "                               \"Gold Plus\": 3,\n",
    "                               \"Platinum\": 4,\n",
    "                               \"Platinum Plus\": 5,\n",
    "                               \"Titanium\": 6,\n",
    "                               \"Titanium Plus\": 7,\n",
    "                               \"Ambassador\": 8})\n",
    "doctors_complaints_merged[\"Rank\"] = doctors_complaints_merged.Rank.astype(\"float\")\n",
    "\n",
    "#Filling Satisfaction missing values\n",
    "median = doctors_complaints_merged.Satisfaction[doctors_complaints_merged.Satisfaction != \"--\"].astype(\"float\").median()\n",
    "doctors_complaints_merged.Satisfaction.replace({\"--\" : median}, inplace = True)\n",
    "doctors_complaints_merged[\"Satisfaction\"] = doctors_complaints_merged.Satisfaction.astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing outliers for more accuracy\n",
    "columns = [\"Rank\", \"Incidence rate\", \"R rate\", \"Satisfaction\", \"Experience\", \"Purchases\", \"Qty\"]\n",
    "\n",
    "#Looping through columns to remove outliers\n",
    "for column in columns:\n",
    "    doctors_complaints_merged = doctors_complaints_merged\\\n",
    "    [(np.abs(stats.zscore(doctors_complaints_merged[column])) < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leaving only numeric variables for ML tasks\n",
    "samples = doctors_complaints_merged.drop([\"DoctorID\", \"Region\", \"Category\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing Standardization\n",
    "scaled_samples = StandardScaler().fit_transform(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing Principal Component Analysis\n",
    "pca = PCA().fit(scaled_samples)\n",
    "\n",
    "#Check how many relevant components there are\n",
    "features = range(pca.n_components_)\n",
    "plt.bar(features, pca.explained_variance_ratio_)\n",
    "plt.xticks(features)\n",
    "plt.xlabel(\"PCA feature #\")\n",
    "plt.ylabel(\"Explained variance on data %\")\n",
    "\n",
    "#Drawing a line where values above make more than 80% of the data\n",
    "plt.axhline(pca.explained_variance_ratio_[np.cumsum(pca.explained_variance_ratio_) >= 0.8][0]\\\n",
    "            , color = \"g\", lw = 0.8, ls = \"--\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"5 PCA features cumulatively explain {round(sum(pca.explained_variance_ratio_[:5]), 3)*100}% of the data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce the dimensionality of the data\n",
    "pca2 = PCA(n_components = 5).fit(scaled_samples)\n",
    "samples_reduced = pca2.transform(scaled_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2_df = pd.DataFrame(abs(pca2.components_), columns= samples.columns, index = [\"PC_1\", \"PC_2\", \"PC_3\", \"PC_4\", \"PC_5\"])\n",
    "pca2_df[pca2_df >= 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using a threshold of 0.5, the most important values of the Principal Components are:\", \"\\n\\n\", \"Component_1: Purchases + Rank\", \"\\n\", \"Component_2: R rate + Experience\", \"\\n\", \"Component_3: Satisfaction + Complaints\", \"\\n\", \"Component_4: Satisfaction + Complaints\", \"\\n\", \"Component_5: R rate + Experience\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing \"elbow\" method to understand how many clusters to divide the data into\n",
    "inertia_values = []\n",
    "for k in range(1, 7):\n",
    "    KM = KMeans(n_clusters = k, random_state=9).fit(samples_reduced)\n",
    "    inertia_values.append(KM.inertia_)\n",
    "plt.plot(range(1, 7), inertia_values, marker = \"o\")\n",
    "plt.xlabel(\"k clusters\")\n",
    "plt.ylabel(\"inertia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting a KMeans model with optimal clusters\n",
    "KM2 = KMeans(n_clusters = 4).fit(samples_reduced)\n",
    "labels = KM2.predict(samples_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a new feature - Complaints to Purchase Ratio\n",
    "doctors_complaints_merged[\"complaints_to_purchaces_ratio\"] = doctors_complaints_merged[\"Qty\"]/ doctors_complaints_merged[\"Purchases\"]\n",
    "\n",
    "#Adding the labels to the data set\n",
    "doctors_complaints_merged[\"persona\"] = labels\n",
    "\n",
    "print(\"Table #1 - Personas average values for each variable\")\n",
    "display(doctors_complaints_merged.iloc[:, 3:].groupby(\"persona\").mean())\n",
    "print(doctors_complaints_merged.persona.value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering doctors that fit personas\n",
    "doctors_complaints_merged[\"persona\"] = doctors_complaints_merged[\"persona\"].astype(\"object\")\n",
    "doctors_complaints_merged[\"persona\"] = doctors_complaints_merged.persona.map({0 : \"Millennial\",\n",
    "                                                                              1 : \"Fan\",\n",
    "                                                                              2 : \"Bootstrapper\",\n",
    "                                                                              3 : \"Conservative\"})\n",
    "\n",
    "dr_persona = doctors_complaints_merged[[\"DoctorID\", \"persona\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Investigating trained labels in orders made for patterns\n",
    "All = doctors.merge(complaints_per_doctor, on = \"DoctorID\", how = \"left\", validate = \"one_to_one\")\\\n",
    "                .merge(instructions, on = \"DoctorID\", how = \"left\", validate = \"one_to_one\")\\\n",
    "                .merge(orders, on = \"DoctorID\", how = \"left\", validate = \"one_to_many\")\\\n",
    "                .merge(dr_persona, on = \"DoctorID\", how = \"right\", validate = \"many_to_one\")\n",
    "\n",
    "All_conditions = All[All[\"Condition C\"].notna()]\n",
    "All_conditions[\"Condition J\"] = All_conditions[\"Condition J\"].fillna(\"Before\")\n",
    "All_conditions[\"Instructions\"] = All_conditions[\"Instructions\"].fillna(\"No\")\n",
    "All_conditions.replace({True : 1,\n",
    "                        False : 0,\n",
    "                        \"Before\" : 0,\n",
    "                        \"After\" : 1,\n",
    "                        \"--\" : 0}, inplace = True)\n",
    "\n",
    "columns = []\n",
    "numeric_columns = All_conditions.describe().columns\n",
    "for column in numeric_columns:\n",
    "    columns.append(column)\n",
    "columns.append(\"persona\")\n",
    "\n",
    "display(All_conditions[columns].groupby(\"persona\").mean())\n",
    "print(\"There is no evident patterns in the Conditions of the orders, that would justify a high level of complaints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quantity of complaints and their type within known labels\n",
    "complaints_personas = dr_persona.merge(complaints, on = \"DoctorID\", how = \"left\", validate = \"one_to_many\")\n",
    "complaints_personas.groupby([\"persona\", \"Complaint Type\"])[\"Qty\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percentage of incorrect complaints per persona\n",
    "complaints_personas_filtered = complaints_personas[complaints_personas[\"Complaint Type\"] == \"Incorrect\"]\n",
    "complaints_personas_filtered.persona.value_counts(normalize = True).sort_values().plot(kind = \"barh\", color = \"#0d5060\")\n",
    "plt.title(\"Percentage of incorrect complaints per persona\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10\n",
    "display(All.sort_values(\"Qty\", ascending = False).head(10))\n",
    "print(\"The top 10 complaint placers, the Doctor ID 'FAICB' had placed an unusual amount of complaints, 6 per order\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
